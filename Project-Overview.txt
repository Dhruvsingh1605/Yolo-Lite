Project: YOLOv4-Tiny Furniture Detection with MLOps Integration

Overview:
This project aims to train and deploy a domain-specific, real-time furniture detection model using YOLOv4-Tiny in TensorFlow. It includes an end-to-end MLOps pipeline with Git, DVC for data/model version control, and MLflow for experiment tracking. The final model is exported to TensorFlow Lite for CPU-based webcam inference.

Directory Structure:

```
project_root/
├── .gitignore           # Specifies files/folders Git should ignore
├── dvc.yaml             # Defines the DVC pipeline stages
├── params.yaml          # Hyperparameters used by DVC stages
├── data/                # Stores dataset
│   ├── raw/             # YOLOv8-formatted raw images and labels
│   └── processed/       # Converted Darknet format, classes.names, train.txt, val.txt
├── models/              # Trained and exported models
│   └── yolov4-tiny/     # Contains weights, SavedModel, TFLite file, metrics
├── logs/                # Timestamped logs for data prep, training, export, evaluation, detection
├── scripts/             # Python scripts driving each pipeline stage
│   ├── prepare_data.py  # Converts YOLOv8 dataset → Darknet format
│   ├── train.py         # Trains YOLOv4-Tiny via Darknet, logs with MLflow
│   ├── evaluate.py      # Computes mAP on validation set, logs metrics
│   ├── export.py        # Converts Darknet weights → TF SavedModel → TFLite
│   └── detect.py        # Runs real-time webcam inference using TFLite model
├── tensorflow-yolov4-tflite/  # External repo for conversion scripts
└── mlruns/              # MLflow experiment logs and artifacts
```

File and Module Descriptions:

1. **.gitignore**: Excludes `data/raw/`, `models/`, `logs/`, and `mlruns/` from Git; these are tracked by DVC and MLflow respectively.

2. **dvc.yaml**: Defines the MLOps pipeline stages:

   * `prepare_data`: Runs `scripts/prepare_data.py`.
   * `train_model`: Runs `scripts/train.py`.
   * `evaluate_model`: Runs `scripts/evaluate.py`.
   * `export_model`: Runs `scripts/export.py`.

3. **params.yaml**: Holds hyperparameters (e.g., epochs, batch\_size, input\_size) for easy tweaking and reproducibility.

4. **data/raw/**: Contains the original dataset in YOLOv8 format, downloaded from Roboflow.

5. **data/processed/**:

   * `classes.names`: List of 5 furniture classes.
   * `train.txt`, `val.txt`: Absolute paths to images for Darknet training.
   * Copied image and label files for consistent directory structure.

6. **models/yolov4-tiny/**:

   * `last.weights`: Final Darknet weights after training.
   * `saved_model/`: TensorFlow SavedModel directory (for inference or further conversion).
   * `yolov4-tiny.tflite`: TensorFlow Lite quantized model for real-time CPU inference.
   * `metrics.json`, `eval_metrics.json`: Stored metrics (loss, mAP) from training and evaluation stages.

7. **logs/**: Timestamped `.log` files from each script (`prepare_data`, `train`, `evaluate`, `export`, `detect`). Enables debugging and auditing every run.

8. **scripts/prepare\_data.py**:

   * Reads `data.yaml` (YOLOv8 format).
   * Generates `data/processed/classes.names`.
   * Scans `train` and `val` folders for images, writes `train.txt` and `val.txt`.
   * Copies images and labels into `data/processed/`.
   * Logs progress and missing files.

9. **scripts/train.py**:

   * Starts an MLflow run.
   * Executes Darknet training command via `subprocess` (using `sys.executable`).
   * Logs hyperparameters and training output (loss, mAP) to MLflow.
   * Saves final weights to `models/yolov4-tiny/last.weights` and as an MLflow artifact.

10. **scripts/evaluate.py**:

    * Starts an MLflow run.
    * Runs Darknet’s `detector map` command to compute mAP.
    * Logs evaluation metrics both in MLflow and `models/yolov4-tiny/eval_metrics.json`.

11. **scripts/export.py**:

    * Uses `save_model.py` from `tensorflow-yolov4-tflite/` to convert `.weights` → TensorFlow SavedModel.
    * Specifies `--classes ../data/processed/classes.names` and other flags (`--model yolov4 --tiny --input_size 320 --framework tf`).
    * Converts SavedModel → TFLite via `tf.lite.TFLiteConverter`.
    * Logs all stdout/stderr and exits on errors.

12. **scripts/detect.py**:

    * Loads TFLite model with `tf.lite.Interpreter` (multi-threaded).
    * Captures webcam frames with OpenCV.
    * Preprocesses (resize/normalize), runs inference, and post-processes boxes.
    * Draws bounding boxes and class labels onscreen in real-time.
    * Logs start and stop times.

13. **tensorflow-yolov4-tflite/**: External TensorFlow implementation of YOLOv4 and conversion scripts (`save_model.py`, `convert_tflite.py`), modified to accept custom classes.

14. **mlruns/**: Generated by MLflow; organizes experiment runs under subfolders containing params, metrics, and logged artifacts (including `.log` files).

Usage:

* Initialize and configure Git, DVC, MLflow as described in the tutorial.
* Run `dvc repro` to execute the full pipeline: data prep → train → evaluate → export.
* Launch MLflow UI (`mlflow ui`) to compare runs and hyperparameters.
* Run `python scripts/detect.py` to start real-time detection via webcam.

This README.txt provides a comprehensive roadmap of the project, detailing how each component interacts to deliver a reproducible, traceable furniture detection system on CPU-only hardware.
